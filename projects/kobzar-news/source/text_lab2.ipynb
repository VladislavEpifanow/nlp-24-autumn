{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjy8v37Pc2fU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjwxKr_sd75I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOO78TmXeDjR"
      },
      "outputs": [],
      "source": [
        "file3 = path+'/records.tsv'\n",
        "\n",
        "df = pd.read_csv(file3, sep=\"\\t\", header=None, names=['word', 'stemm', 'lemm'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xVzNGj2e3-i"
      },
      "outputs": [],
      "source": [
        "words = list(df['word'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3qENirWyLn_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqlZ8VFGqB7L"
      },
      "outputs": [],
      "source": [
        "for i in range(len(words)):\n",
        "    el = re.sub('\\n', '', str(words[i]))\n",
        "    el = re.sub('[\\.{1,}!?,:;\\(\\)\\\"\\[\\]]', '', str(el))\n",
        "    el = el.lower()\n",
        "    words[i] = el\n",
        "\n",
        "words = [el for el in words if el not in stopwords.words('english')]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDJp9Or_5iMf"
      },
      "outputs": [],
      "source": [
        "trigramms = []\n",
        "\n",
        "for i in range(len(words)-2):\n",
        "    trigramms.append((words[i], words[i+1], words[i+2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ6MNed16KZ5"
      },
      "outputs": [],
      "source": [
        "num_3 = len(trigramms)\n",
        "\n",
        "p_tri = {}\n",
        "\n",
        "for tri in trigramms:\n",
        "    if tri in p_tri:\n",
        "        p_tri[tri] += 1\n",
        "    else:\n",
        "        p_tri[tri] = 1\n",
        "\n",
        "\n",
        "p_w = {}\n",
        "\n",
        "for w in words:\n",
        "    if w in p_w:\n",
        "        p_w[w] += 1\n",
        "    else:\n",
        "        p_w[w] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKxiE1B9VhsX"
      },
      "outputs": [],
      "source": [
        "def MI():\n",
        "\n",
        "    mi_score = []\n",
        "\n",
        "    N = 3\n",
        "    S = len(words)\n",
        "\n",
        "    for i, tri in enumerate(trigramms):\n",
        "        w1, w2, w3 = words[i], words[i+1], words[i+2]\n",
        "\n",
        "        mi = np.log2((S ** 2) * (p_tri[tri])/(p_w[w1] * p_w[w2] * p_w[w3]))\n",
        "        mi_score.append((mi, tri))\n",
        "\n",
        "    return mi_score\n",
        "\n",
        "mi_score =  MI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOOHY8BqE06J"
      },
      "outputs": [],
      "source": [
        "sorted_mi_score = sorted(mi_score, key=lambda t: (-t[0], t[1][0], t[1][1], t[1][2]))\n",
        "sorted_mi_score[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gQ01p7kFvIj"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "\n",
        "text = ' '.join(words)\n",
        "\n",
        "tokens = nltk.word_tokenize(text,'english',True)\n",
        "\n",
        "text = nltk.Text(tokens)\n",
        "\n",
        "\n",
        "finder_thr = TrigramCollocationFinder.from_words(text)\n",
        "\n",
        "for i in finder_thr.score_ngrams(trigram_measures.pmi)[:30]:\n",
        "    print(i)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}