{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyDU-I7F2XCU"
      },
      "outputs": [],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "xxg4fKVq2zMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive'\n",
        "\n",
        "file4 = path + '/train.txt'\n",
        "file5 = path + '/test.txt'"
      ],
      "metadata": {
        "id": "aMd_D41r5wic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file3 = path+'/records.tsv'\n",
        "\n",
        "df = pd.read_csv(file3, sep=\"\\t\", header=None, names=['word', 'stemm', 'lemm'])\n",
        "words = list(df['word'])"
      ],
      "metadata": {
        "id": "i03_3xh6qSX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_sentences_init(text):\n",
        "\n",
        "    sents = []\n",
        "\n",
        "    text0 = re.sub('\\n', ' ', text)\n",
        "    text0 = re.sub('\\s$|\\\"', '', text0)\n",
        "\n",
        "    text1 = re.split('\\s{2,}', text0)\n",
        "    sents.append(text1[0]+'.')\n",
        "\n",
        "    text2 = ' '.join(text1[1:])\n",
        "\n",
        "    text3 = re.split('(?<=[.!?]) +', text2)\n",
        "\n",
        "    text3 = [t for t in text3 if t != '']\n",
        "\n",
        "    sents += text3\n",
        "\n",
        "\n",
        "\n",
        "    return sents\n",
        "\n",
        "def split_into_words_init(sents):\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for s in sents:\n",
        "\n",
        "        s0 = re.sub('xc2xa', '', s)\n",
        "\n",
        "        s0 = re.sub(' ', '__probel__', s0)\n",
        "\n",
        "        s0 = re.sub('(?<=(Dr|Mr|Ms))(__probel__)(?=[A-Z])', ' ', s0)\n",
        "\n",
        "\n",
        "        w = re.split('__probel__', s0)\n",
        "        w = [w_i for w_i in w if w_i != '' and w_i != '-']\n",
        "        words.append(w)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "EvIcjThrMYfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_sentences(text):\n",
        "\n",
        "\n",
        "    sents = []\n",
        "    for txt in text:\n",
        "        txt_s = []\n",
        "\n",
        "        text0 = re.sub('\\n', ' ', txt)\n",
        "        text0 = re.sub('\\s$|\\\"', '', text0)\n",
        "\n",
        "        text1 = re.split('\\s{2,}', text0)\n",
        "        txt_s.append(text1[0]+'.')\n",
        "\n",
        "        text2 = ' '.join(text1[1:])\n",
        "\n",
        "        text3 = re.split('(?<=[.!?]) +', text2)\n",
        "\n",
        "        text3 = [t for t in text3 if t != '']\n",
        "\n",
        "        txt_s += text3\n",
        "\n",
        "        sents.append(txt_s)\n",
        "\n",
        "    return sents\n",
        "\n",
        "def split_into_words(texts):\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for txt in texts:\n",
        "        sent_words = []\n",
        "        for s in txt:\n",
        "\n",
        "            s0 = re.sub('xc2xa', '', s)\n",
        "\n",
        "            s0 = re.sub(' ', '__probel__', s0)\n",
        "\n",
        "            s0 = re.sub('(?<=(Dr|Mr|Ms))(__probel__)(?=[A-Z])', ' ', s0)\n",
        "\n",
        "\n",
        "            w = re.split('__probel__', s0)\n",
        "            w = [re.sub('[\\.{1,}!?,:;\\(\\)\\\"\\[\\]\\'\\s]', '', str(w_i)).lower() for w_i in w if w_i != '' and w_i != '-']\n",
        "\n",
        "            sent_words.append(w)\n",
        "\n",
        "        words.append(sent_words)\n",
        "\n",
        "\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "A3Fr27SYsZl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = open(file4)\n",
        "s_tr = train.read()\n",
        "\n",
        "test = open(file5)\n",
        "s_tst = test.read()\n",
        "\n",
        "s_trn_spl = re.split('\\_{5}', s_tr)\n",
        "s_tst_spl = re.split('\\_{5}', s_tst)"
      ],
      "metadata": {
        "id": "H-d9Bqjrs-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents = split_into_sentences_init(s_tr)\n",
        "train_w = split_into_words_init(train_sents)"
      ],
      "metadata": {
        "id": "nDdaAakvt_vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "model = gensim.models.Word2Vec(train_w, min_count=5,\n",
        "                     window=7,\n",
        "                     vector_size=800)\n"
      ],
      "metadata": {
        "id": "h0G2Y_-72_4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosim(a, b):\n",
        "    a_v = np.array(model.wv[a])\n",
        "    b_v = np.array(model.wv[b])\n",
        "\n",
        "    return 1-np.dot(a_v, b_v)/(norm(a_v)*norm(b_v))"
      ],
      "metadata": {
        "id": "wWhoL_x3HVEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosim('performer', 'singer'))\n",
        "print(cosim('performer', 'musician'))\n",
        "\n",
        "print()\n",
        "print(cosim('performer', 'art'))\n",
        "print(cosim('performer', 'show'))\n",
        "print()\n",
        "print(cosim('performer', 'users'))\n",
        "print(cosim('performer', 'government'))"
      ],
      "metadata": {
        "id": "c56BeGzCoJgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosim('mobile', 'phone'))\n",
        "print(cosim('device', 'phone'))\n",
        "print()\n",
        "print(cosim('phone', 'game'))\n",
        "print(cosim('phone', 'number'))\n",
        "print()\n",
        "print(cosim('phone', 'car'))\n",
        "print(cosim('phone', 'month'))"
      ],
      "metadata": {
        "id": "szOeO5h_od_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(tx):\n",
        "    sents = split_into_sentences(tx)\n",
        "    w = split_into_words(sents)\n",
        "\n",
        "\n",
        "    embs = []\n",
        "    for el in w: #text lvl\n",
        "        l_el1 = []\n",
        "        for el2 in el: #sents lvl\n",
        "            l_el2 = []\n",
        "            for el3 in el2: #words lvl\n",
        "\n",
        "                try:\n",
        "                    l_el2.append(model.wv[el3])\n",
        "                except KeyError:\n",
        "                    pass\n",
        "            if len(l_el2) > 0:\n",
        "                l_el1.append(l_el2)\n",
        "        if len(l_el1) > 0:\n",
        "            embs.append(l_el1)\n",
        "\n",
        "\n",
        "    s_m = []\n",
        "    for el1 in embs:\n",
        "        s_m2 = [] #mean (text) by sent\n",
        "        for el2 in el1:\n",
        "            s_m3 = [] #mean (sent) by words\n",
        "            for el3 in el2:\n",
        "                s_m3.append(el3)\n",
        "            s_m2.append(sum(s_m3) / len(s_m3))\n",
        "        s_m.append(sum(s_m2) / len(s_m2))\n",
        "\n",
        "    return s_m, s_m2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Iqzvecpm-nmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_m, s_m2 = vectorize_text(s_trn_spl) #train"
      ],
      "metadata": {
        "id": "KmPPC-Ib_cID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_m_t, s_m2_t = vectorize_text(s_tst_spl) #test"
      ],
      "metadata": {
        "id": "q27A4mt9whP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "file = path+'/train_lab3.tsv'\n",
        "\n",
        "try:\n",
        "    os.remove(file)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "with open(file, 'w', newline='') as tsvfile:\n",
        "        writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
        "\n",
        "        for i, embed in enumerate(s_m):\n",
        "            writer.writerow([i] + list(embed))\n",
        "\n",
        "        size = tsvfile.truncate()\n",
        "        size = tsvfile.truncate(size - 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "or_3n4BMiBxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = path+'/test_lab3.tsv'\n",
        "\n",
        "try:\n",
        "    os.remove(file)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "with open(file, 'w', newline='') as tsvfile:\n",
        "        writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
        "\n",
        "        for i, embed in enumerate(s_m_t):\n",
        "            writer.writerow([i] + list(embed))\n",
        "\n",
        "        size = tsvfile.truncate()\n",
        "        size = tsvfile.truncate(size - 2)"
      ],
      "metadata": {
        "id": "kui9jqiHwon8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}